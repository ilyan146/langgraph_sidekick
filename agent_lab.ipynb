{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4420b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph.message import add_messages # A reducer function\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated\n",
    "from databricks_langchain import ChatDatabricks\n",
    "import os\n",
    "from client import AzureAIClient\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pydantic import BaseModel\n",
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "import aiosqlite\n",
    "from agent_tools import get_agent_tools, get_playwright_tools\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ae566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple state\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# Get llms\n",
    "llm_db = ChatDatabricks(endpoint=\"databricks-claude-3-7-sonnet\", max_tokens=1000)\n",
    "\n",
    "llm_az = AzureChatOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_ad_token_provider=AzureAIClient().token_provider,\n",
    "    azure_deployment=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tools\n",
    "tools_list = await get_agent_tools()\n",
    "playwright_tools, browser, playwright = await get_playwright_tools()\n",
    "\n",
    "agent_tools = tools_list + playwright_tools\n",
    "print(agent_tools)\n",
    "\n",
    "# Give the llm the tools\n",
    "llm_with_tools = llm_az.bind_tools(agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050717d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in agent_tools:\n",
    "    print(f\"Tool Name: {tool.name} == {tool}\")\n",
    "\n",
    "# Drop the serper tool for testing the playwright tool\n",
    "agent_tools = [tool for tool in agent_tools if tool.name != \"google_serper_search_tool\"]\n",
    "print(\"\\n\\n\", agent_tools)\n",
    "for tool in agent_tools:\n",
    "    print(f\"Tool Name: {tool.name} == {tool}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0390347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory database\n",
    "db_path=\"memory_db/sqlite_memory.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "async def setup_async_db():\n",
    "    async_conn = await aiosqlite.connect(db_path)\n",
    "    return async_conn\n",
    "\n",
    "async_conn = await setup_async_db()\n",
    "\n",
    "# sql_memory = SqliteSaver(conn)\n",
    "sql_memory = AsyncSqliteSaver(async_conn)\n",
    "\n",
    "# memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat function\n",
    "def chat(state: State) -> State:\n",
    "    response = llm_with_tools.invoke(state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7add86f",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(state_schema=State)\n",
    "\n",
    "graph_builder.add_edge(START, \"chat\")\n",
    "graph_builder.add_node(\"chat\", chat)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=agent_tools))\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chat\", tools_condition, \"tools\")\n",
    "graph_builder.add_edge(\"tools\", \"chat\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=sql_memory)\n",
    "# graph = graph_builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958cb20",
   "metadata": {},
   "source": [
    "### Create gradio chat function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "async def gradio_chat(user_input: str, history):\n",
    "    state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    response = await graph.ainvoke(state, config=config) # Config sets the thread to use in memory\n",
    "    print(response)\n",
    "\n",
    "    return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa847aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat interface\n",
    "gr.ChatInterface(gradio_chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5b42b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04a4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
